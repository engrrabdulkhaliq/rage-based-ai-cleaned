{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e2264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âš¡ Audio Transcription + Translation (Hindi â†’ English)\n",
      "============================================================\n",
      "Settings: Max 5 parallel chunks, 10min chunks\n",
      "\n",
      "âœ“ Found 4 file(s): ['video1.mp3', 'video2.mp3', 'video3.mp3', 'video4.mp3']\n",
      "\n",
      "\n",
      "[1/4] video1.mp3\n",
      "\n",
      "============================================================\n",
      "Processing: video1.mp3\n",
      "============================================================\n",
      "  File size: 36.75 MB\n",
      "  File too large, will use chunking...\n",
      "  Loading audio for chunking...\n",
      "  Duration: 41.8 minutes\n",
      "  Creating 5 chunks of ~10 minutes each\n",
      "\n",
      "  Processing 5 chunks in parallel (max 5 at a time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:38<01:04, 21.51s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 3 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7139, Requested 600. Please try again in 4m29.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:46<00:30, 15.20s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 1 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7123, Requested 600. Please try again in 4m21.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:46<00:09,  9.30s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 2 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7123, Requested 600. Please try again in 4m21.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:47<00:00,  9.55s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 0 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7121, Requested 600. Please try again in 4m20.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "  âš  Warning: 4 chunks failed\n",
      "\n",
      "  âœ“ Completed in 57.5 seconds\n",
      "    Hindi: 22 segments | English: 22 segments\n",
      "  ðŸ’¾ Saved: video1_HINDI.txt\n",
      "  ðŸ’¾ Saved: video1_ENGLISH.txt\n",
      "  ðŸ’¾ Saved: video1_COMBINED.txt\n",
      "\n",
      "[2/4] video2.mp3\n",
      "\n",
      "============================================================\n",
      "Processing: video2.mp3\n",
      "============================================================\n",
      "  File size: 14.42 MB\n",
      "  Transcribing directly (Hindi + English)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7111, Requested 834. Please try again in 6m12.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n",
      "  Loading audio for chunking...\n",
      "  Duration: 13.9 minutes\n",
      "  Creating 2 chunks of ~10 minutes each\n",
      "\n",
      "  Processing 2 chunks in parallel (max 5 at a time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.15s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 1 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7097, Requested 234. Please try again in 1m5.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.91s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 0 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7079, Requested 600. Please try again in 3m59.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "  âš  Warning: 2 chunks failed\n",
      "\n",
      "  âœ“ Completed in 20.8 seconds\n",
      "    Hindi: 0 segments | English: 0 segments\n",
      "  âœ— Failed to transcribe video2.mp3\n",
      "\n",
      "[3/4] video3.mp3\n",
      "\n",
      "============================================================\n",
      "Processing: video3.mp3\n",
      "============================================================\n",
      "  File size: 67.57 MB\n",
      "  File too large, will use chunking...\n",
      "  Loading audio for chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Duration: 82.3 minutes\n",
      "  Creating 9 chunks of ~10 minutes each\n",
      "\n",
      "  Processing 9 chunks in parallel (max 5 at a time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  11%|â–ˆ         | 1/9 [00:40<05:26, 40.86s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 4 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 6951, Requested 600. Please try again in 2m55.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  22%|â–ˆâ–ˆâ–       | 2/9 [00:46<02:21, 20.28s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 1 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 6939, Requested 600. Please try again in 2m49.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:49<01:12, 12.09s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 2 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 6934, Requested 600. Please try again in 2m47s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:49<00:37,  7.51s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 3 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 6933, Requested 600. Please try again in 2m46.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:50<00:19,  4.97s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 0 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 6932, Requested 600. Please try again in 2m46s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [01:00<00:20,  6.74s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 5 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7189, Requested 600. Please try again in 4m54.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [01:04<00:04,  4.47s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 6 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7180, Requested 600. Please try again in 4m50s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [01:07<00:00,  7.47s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 7 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7175, Requested 600. Please try again in 4m47.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "  âš  Warning: 8 chunks failed\n",
      "\n",
      "  âœ“ Completed in 90.8 seconds\n",
      "    Hindi: 44 segments | English: 23 segments\n",
      "  ðŸ’¾ Saved: video3_HINDI.txt\n",
      "  ðŸ’¾ Saved: video3_ENGLISH.txt\n",
      "  ðŸ’¾ Saved: video3_COMBINED.txt\n",
      "\n",
      "[4/4] video4.mp3\n",
      "\n",
      "============================================================\n",
      "Processing: video4.mp3\n",
      "============================================================\n",
      "  File size: 46.37 MB\n",
      "  File too large, will use chunking...\n",
      "  Loading audio for chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Duration: 54.5 minutes\n",
      "  Creating 6 chunks of ~10 minutes each\n",
      "\n",
      "  Processing 6 chunks in parallel (max 5 at a time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  17%|â–ˆâ–‹        | 1/6 [00:23<01:56, 23.23s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 4 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7106, Requested 600. Please try again in 4m12.999999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:27<00:49, 12.28s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 2 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7097, Requested 600. Please try again in 4m8.499999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:30<00:23,  7.80s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 3 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7092, Requested 600. Please try again in 4m5.999999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:30<00:09,  4.88s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 5 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7091, Requested 271. Please try again in 1m21s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:31<00:03,  3.26s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 1 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7090, Requested 600. Please try again in 4m4.999999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Transcribing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:32<00:00,  5.47s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  âœ— Chunk 0 failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `whisper-large-v3` in organization `org_01kf2rwmz8eve8tavv6nj09hhj` service tier `on_demand` on seconds of audio per hour (ASPH): Limit 7200, Used 7087, Requested 600. Please try again in 4m3.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'seconds', 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "  âš  Warning: 6 chunks failed\n",
      "\n",
      "  âœ“ Completed in 43.9 seconds\n",
      "    Hindi: 0 segments | English: 0 segments\n",
      "  âœ— Failed to transcribe video4.mp3\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ All files completed in 212.9 seconds!\n",
      "ðŸ“ Results in 'transcriptions' folder\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from openai import OpenAI\n",
    "from pydub import AudioSegment\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Groq API key setup (FREE!)\n",
    "API_KEY = \"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\"  \n",
    "client = Groq(api_key=\"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\")\n",
    "OPENAI_API_KEY = \"sk-AfX0rModIomRG94i_uu6EmTxDke-lTJjrd-ypIa0mVT3BlbkFJGWF5LOwnni53vOR9uvHv2FU_H98V4-DHOqp87EP1gA\"  # Apni puri key yahan daalo\n",
    "client = OpenAI(api_key=\"sk-AfX0rModIomRG94i_uu6EmTxDke-lTJjrd-ypIa0mVT3BlbkFJGWF5LOwnni53vOR9uvHv2FU_H98V4-DHOqp87EP1gA\")\n",
    "# Folders setup\n",
    "audio_folder = \"audios\"\n",
    "output_folder = \"transcriptions\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "MAX_WORKERS = 5  \n",
    "CHUNK_LENGTH_MS = 600000  \n",
    "def transcribe_audio_direct(audio_path):\n",
    "   \n",
    "    try:\n",
    "        file_size = os.path.getsize(audio_path) / (1024 * 1024)  \n",
    "        \n",
    "        print(f\"  File size: {file_size:.2f} MB\")\n",
    "        \n",
    "        if file_size < 24: \n",
    "            print(f\"  Transcribing directly (Hindi + English)...\")\n",
    "            \n",
    "           \n",
    "            with open(audio_path, \"rb\") as audio_file:\n",
    "                hindi_transcript = client.audio.transcriptions.create(\n",
    "                    model=\"whisper-large-v3\",\n",
    "                    file=audio_file,\n",
    "                    response_format=\"verbose_json\",\n",
    "                    language=\"hi\",\n",
    "                    temperature=0.0\n",
    "                )\n",
    "            \n",
    "            # English translation\n",
    "            with open(audio_path, \"rb\") as audio_file:\n",
    "                english_transcript = client.audio.translations.create(\n",
    "                    model=\"whisper-large-v3\",\n",
    "                    file=audio_file,\n",
    "                    response_format=\"verbose_json\",\n",
    "                    temperature=0.0\n",
    "                )\n",
    "            \n",
    "            return [(hindi_transcript, english_transcript)], False\n",
    "        else:\n",
    "            print(f\"  File too large, will use chunking...\")\n",
    "            return None, True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        return None, True\n",
    "\n",
    "def split_and_transcribe_chunk(args):\n",
    " \n",
    "    audio, chunk_idx, start_ms, end_ms, audio_name = args\n",
    "    \n",
    "    try:\n",
    "        chunk = audio[start_ms:end_ms]\n",
    "        temp_path = f\"temp_chunk_{audio_name}_{chunk_idx}.mp3\"\n",
    "        chunk.export(temp_path, format=\"mp3\")\n",
    "        \n",
    "        # Hindi Transcription\n",
    "        with open(temp_path, \"rb\") as audio_file:\n",
    "            hindi_transcript = client.audio.transcriptions.create(\n",
    "                model=\"whisper-large-v3\",\n",
    "                file=audio_file,\n",
    "                response_format=\"verbose_json\",\n",
    "                language=\"hi\",\n",
    "                temperature=0.0\n",
    "            )\n",
    "        \n",
    "        # English Translation\n",
    "        with open(temp_path, \"rb\") as audio_file:\n",
    "            english_transcript = client.audio.translations.create(\n",
    "                model=\"whisper-large-v3\",\n",
    "                file=audio_file,\n",
    "                response_format=\"verbose_json\",\n",
    "                temperature=0.0\n",
    "            )\n",
    "        \n",
    "        os.remove(temp_path)\n",
    "        \n",
    "        start_sec = start_ms / 1000\n",
    "        if hasattr(hindi_transcript, 'segments') and hindi_transcript.segments:\n",
    "            for segment in hindi_transcript.segments:\n",
    "                segment['start'] += start_sec\n",
    "                segment['end'] += start_sec\n",
    "        \n",
    "        if hasattr(english_transcript, 'segments') and english_transcript.segments:\n",
    "            for segment in english_transcript.segments:\n",
    "                segment['start'] += start_sec\n",
    "                segment['end'] += start_sec\n",
    "        \n",
    "        return {\n",
    "            'chunk_idx': chunk_idx,\n",
    "            'hindi_transcript': hindi_transcript,\n",
    "            'english_transcript': english_transcript,\n",
    "            'start': start_sec,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n  âœ— Chunk {chunk_idx} failed: {e}\")\n",
    "        return {\n",
    "            'chunk_idx': chunk_idx,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def process_with_chunking(audio_path):\n",
    "    \"\"\"\n",
    "    Badi files ke liye parallel chunking use karta hai\n",
    "    \"\"\"\n",
    "    print(f\"  Loading audio for chunking...\")\n",
    "    audio = AudioSegment.from_mp3(audio_path)\n",
    "    \n",
    "    total_duration_ms = len(audio)\n",
    "    num_chunks = (total_duration_ms + CHUNK_LENGTH_MS - 1) // CHUNK_LENGTH_MS\n",
    "    \n",
    "    print(f\"  Duration: {total_duration_ms/1000/60:.1f} minutes\")\n",
    "    print(f\"  Creating {num_chunks} chunks of ~{CHUNK_LENGTH_MS/1000/60:.0f} minutes each\")\n",
    "    \n",
    "    chunk_args = []\n",
    "    audio_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start_ms = i * CHUNK_LENGTH_MS\n",
    "        end_ms = min((i + 1) * CHUNK_LENGTH_MS, total_duration_ms)\n",
    "        chunk_args.append((audio, i, start_ms, end_ms, audio_name))\n",
    "    \n",
    "    # Parallel processing with progress bar\n",
    "    results = []\n",
    "    print(f\"\\n  Processing {num_chunks} chunks in parallel (max {MAX_WORKERS} at a time)...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {executor.submit(split_and_transcribe_chunk, arg): i \n",
    "                  for i, arg in enumerate(chunk_args)}\n",
    "        \n",
    "        with tqdm(total=num_chunks, desc=\"  Transcribing\", unit=\"chunk\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                pbar.update(1)\n",
    "    \n",
    "    results.sort(key=lambda x: x['chunk_idx'])\n",
    "    \n",
    "    hindi_transcripts = [r['hindi_transcript'] for r in results if r['success']]\n",
    "    english_transcripts = [r['english_transcript'] for r in results if r['success']]\n",
    "    \n",
    "    failed = sum(1 for r in results if not r['success'])\n",
    "    if failed > 0:\n",
    "        print(f\"\\n  âš  Warning: {failed} chunks failed\")\n",
    "    \n",
    "    return hindi_transcripts, english_transcripts\n",
    "\n",
    "def process_audio_file(audio_path):\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {os.path.basename(audio_path)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    transcripts, needs_chunking = transcribe_audio_direct(audio_path)\n",
    "    \n",
    "    if needs_chunking:\n",
    "        hindi_transcripts, english_transcripts = process_with_chunking(audio_path)\n",
    "    else:\n",
    "        hindi_transcripts = [t[0] for t in transcripts]\n",
    "        english_transcripts = [t[1] for t in transcripts]\n",
    "    \n",
    "    hindi_segments = []\n",
    "    for transcript in hindi_transcripts:\n",
    "        if hasattr(transcript, 'segments') and transcript.segments:\n",
    "            for segment in transcript.segments:\n",
    "                hindi_segments.append({\n",
    "                    \"start\": segment['start'],\n",
    "                    \"end\": segment['end'],\n",
    "                    \"text\": segment['text'].strip()\n",
    "                })\n",
    "        elif hasattr(transcript, 'text'):\n",
    "            hindi_segments.append({\"start\": 0, \"end\": 0, \"text\": transcript.text})\n",
    "    \n",
    "   \n",
    "    english_segments = []\n",
    "    for transcript in english_transcripts:\n",
    "        if hasattr(transcript, 'segments') and transcript.segments:\n",
    "            for segment in transcript.segments:\n",
    "                english_segments.append({\n",
    "                    \"start\": segment['start'],\n",
    "                    \"end\": segment['end'],\n",
    "                    \"text\": segment['text'].strip()\n",
    "                })\n",
    "        elif hasattr(transcript, 'text'):\n",
    "            english_segments.append({\"start\": 0, \"end\": 0, \"text\": transcript.text})\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n  âœ“ Completed in {elapsed:.1f} seconds\")\n",
    "    print(f\"    Hindi: {len(hindi_segments)} segments | English: {len(english_segments)} segments\")\n",
    "    \n",
    "    return hindi_segments, english_segments\n",
    "\n",
    "def save_transcription(audio_name, hindi_segments, english_segments):\n",
    "  \n",
    "    base_name = os.path.splitext(audio_name)[0]\n",
    "    \n",
    "  \n",
    "    hindi_txt = os.path.join(output_folder, f\"{base_name}_HINDI.txt\")\n",
    "    with open(hindi_txt, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"HINDI TRANSCRIPTION: {audio_name}\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        for item in hindi_segments:\n",
    "            m, s = int(item['start']//60), int(item['start']%60)\n",
    "            em, es = int(item['end']//60), int(item['end']%60)\n",
    "            f.write(f\"[{m:02d}:{s:02d} - {em:02d}:{es:02d}] {item['text']}\\n\")\n",
    "    \n",
    "    # English TXT\n",
    "    english_txt = os.path.join(output_folder, f\"{base_name}_ENGLISH.txt\")\n",
    "    with open(english_txt, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"ENGLISH TRANSLATION: {audio_name}\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        for item in english_segments:\n",
    "            m, s = int(item['start']//60), int(item['start']%60)\n",
    "            em, es = int(item['end']//60), int(item['end']%60)\n",
    "            f.write(f\"[{m:02d}:{s:02d} - {em:02d}:{es:02d}] {item['text']}\\n\")\n",
    "    \n",
    "    # Combined TXT\n",
    "    combined_txt = os.path.join(output_folder, f\"{base_name}_COMBINED.txt\")\n",
    "    with open(combined_txt, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"HINDI + ENGLISH: {audio_name}\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        for i in range(max(len(hindi_segments), len(english_segments))):\n",
    "            if i < len(hindi_segments):\n",
    "                item = hindi_segments[i]\n",
    "                m, s = int(item['start']//60), int(item['start']%60)\n",
    "                em, es = int(item['end']//60), int(item['end']%60)\n",
    "                f.write(f\"[{m:02d}:{s:02d} - {em:02d}:{es:02d}]\\n\")\n",
    "                f.write(f\"HINDI: {item['text']}\\n\")\n",
    "                if i < len(english_segments):\n",
    "                    f.write(f\"ENGLISH: {english_segments[i]['text']}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"  ðŸ’¾ Saved: {base_name}_HINDI.txt\")\n",
    "    print(f\"  ðŸ’¾ Saved: {base_name}_ENGLISH.txt\")\n",
    "    print(f\"  ðŸ’¾ Saved: {base_name}_COMBINED.txt\")\n",
    "\n",
    "def main():\n",
    "   \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âš¡ Audio Transcription + Translation (Hindi â†’ English)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Settings: Max {MAX_WORKERS} parallel chunks, {CHUNK_LENGTH_MS/1000/60:.0f}min chunks\")\n",
    "    \n",
    "\n",
    "    audio_files = [f for f in os.listdir(audio_folder) if f.endswith('.mp3')]\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(f\"\\nâœ— No MP3 files in '{audio_folder}' folder!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nâœ“ Found {len(audio_files)} file(s): {audio_files}\\n\")\n",
    "    \n",
    "    total_start = time.time()\n",
    "    \n",
    "    \n",
    "    for idx, audio_file in enumerate(sorted(audio_files), 1):\n",
    "        print(f\"\\n[{idx}/{len(audio_files)}] {audio_file}\")\n",
    "        \n",
    "        audio_path = os.path.join(audio_folder, audio_file)\n",
    "        hindi_segments, english_segments = process_audio_file(audio_path)\n",
    "        \n",
    "        if hindi_segments and english_segments:\n",
    "            save_transcription(audio_file, hindi_segments, english_segments)\n",
    "        else:\n",
    "            print(f\"  âœ— Failed to transcribe {audio_file}\")\n",
    "    \n",
    "    total_time = time.time() - total_start\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸŽ‰ All files completed in {total_time:.1f} seconds!\")\n",
    "    print(f\"ðŸ“ Results in '{output_folder}' folder\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac9c473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
